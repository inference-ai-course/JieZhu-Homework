{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer in the\u000b",
    "Generative AI Era \n",
    "## lecture 1 - Prompt Engineering with Jupyter Notebook \n",
    "### Introduction\n",
    "This notebook introduces prompt engineering techniques to effectively interact with large language models (LLMs). You'll learn how to craft prompts for various tasks, including summarization, inference, transformation, and expansion\n",
    "\n",
    "### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openai\n",
      "  Using cached openai-1.97.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\montr\\appdata\\roaming\\python\\python313\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\montr\\appdata\\roaming\\python\\python313\\site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\montr\\appdata\\roaming\\python\\python313\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\programdata\\miniconda3\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\programdata\\miniconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\programdata\\miniconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\montr\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\montr\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\programdata\\miniconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\miniconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Using cached openai-1.97.1-py3-none-any.whl (764 kB)\n",
      "Downloading jiter-0.10.0-cp313-cp313-win_amd64.whl (205 kB)\n",
      "Installing collected packages: jiter, openai\n",
      "\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   ---------------------------------------- 2/2 [openai]\n",
      "\n",
      "Successfully installed jiter-0.10.0 openai-1.97.1\n"
     ]
    }
   ],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries and set your OpenAI API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = openai.OpenAI(api_key='xxxxxxx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Basic Prompting\n",
    "Let's start with a simple prompt to generate a response from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "def get_completion(prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example usage\n",
    "prompt = \"What is the capital of France?\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Germany is Berlin.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: Modify the prompt to ask about the capital of Germany.\n",
    "prompt = \"What is the capital of Germany?\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Summarization\n",
    "You can use prompts to summarize text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is the simulation of human intelligence in machines designed to think and learn, with applications in fields such as healthcare, finance, and transportation.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and learn. It has applications in various fields, including healthcare, finance, and transportation.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Summarize the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snyk's Security Labs team consists of leading application security researchers who proactively identify vulnerabilities in software and open source projects before they are publicly known. This research is essential for strong DevSecOps programs. Recently, Snyk has expanded its focus to AI-related research, highlighted by the addition of Invariant Labs, a team with expertise in securing AI systems, particularly AI agents. Originating from ETH Zurich, Invariant Labs has gained recognition for ensuring the safety and trustworthiness of autonomous AI, winning awards such as the SafeBench competition for their \"AgentDojo\" project. Their research aligns well with Snyk's mission and culture.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: Try summarizing a longer article or passage of your choice.\n",
    "\n",
    "text = \"\"\"\n",
    "Snyk prides itself on employing some of the leading researchers in the field of application security as part of our dedicated Security Labs team. These experts are always digging into new vulnerabilities, often uncovering major issues in key software and open source projects long before they hit public databases. All this in-depth, proactive research has long been a cornerstone of our value in enabling strong DevSecOps programs. In recent years, we’ve extended that into a variety of AI-related research areas, and today’s addition provides a major boost to this branch of our research and thought leadership. Invariant Labs boasts an impressive team with deep expertise in securing AI systems, particularly AI agents. Spun out of ETH Zurich (just like the Deepcode AI team that became the backbone of Snyk’s $100M+ AI Native Static Code analysis product), their team includes top AI and security researchers who have built a reputation through ensuring that as AI becomes more autonomous, it remains trustworthy and safe to use. They’ve won numerous awards, including the prestigious SafeBench competition, where their “AgentDojo” project took home first prize. Their deep focus on research fits so neatly into the Snyk mission and culture.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Summarize the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Information Extraction\n",
    "Extract specific information from a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: John Doe  \n",
      "Occupation: Research Scientist\n",
      "Name: John Doe  \n",
      "Occupation: Research Scientist\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "John Doe, a 29-year-old software engineer from San Francisco, recently joined OpenAI as a research scientist.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Extract the name and occupation from the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "text = \"\"\"\n",
    "John Doe, a 29-year-old software engineer from San Francisco, recently joined OpenAI as a research scientist.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Extract the name and occupation from the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: 29  \n",
      "Location: San Francisco\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: Extract the age and location from the same text.\n",
    "text = \"\"\"\n",
    "John Doe, a 29-year-old software engineer from San Francisco, recently joined OpenAI as a research scientist.\n",
    "\"\"\"\n",
    "prompt = f\"Extract the age and location from the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Transformation\n",
    "Transform text from one format or style to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le temps est agréable aujourd'hui.\n"
     ]
    }
   ],
   "source": [
    "text = \"The weather is nice today.\"\n",
    "\n",
    "prompt = f\"Translate the following text to French:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El clima está agradable hoy.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: Translate a different sentence to Spanish.\n",
    "\n",
    "text = \"The weather is nice today.\"\n",
    "\n",
    "prompt = f\"Translate the following text to Spanish:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Expansion\n",
    "Expand a short prompt into a more detailed response.​\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in the misty mountains of Eldoria, there lived a dragon named Zephyr. Unlike the other dragons who reveled in hoarding gold and terrorizing villages, Zephyr had a curious mind and a heart full of dreams. He often gazed down from his lofty perch, watching the humans below as they tapped away at their glowing screens, creating wondrous things with their strange symbols and languages.\n",
      "\n",
      "One day, while exploring a forgotten cave, Zephyr stumbled upon an ancient tome. Its pages were filled with intricate diagrams and strange characters. As he flipped through the book, he realized it was a guide to coding—a language that could bring ideas to life through the magic of technology. Intrigued, Zephyr decided he would learn to code.\n",
      "\n",
      "At first, it was a daunting task. His massive claws were not suited for the delicate tapping of a keyboard. But Zephyr was determined. He fashioned a makeshift keyboard from stones and twigs, and with a little help from the wind, he learned to manipulate the keys with his breath. The first few lines of code were clumsy, but with each attempt, he grew more adept.\n",
      "\n",
      "Days turned into weeks, and Zephyr immersed himself in the world of programming. He learned about variables, loops, and functions, and soon he was creating simple programs that made the wind dance and the clouds swirl. The other dragons watched in bewilderment as Zephyr transformed from a fearsome beast into a master of code.\n",
      "\n",
      "One fateful day, a terrible storm swept through Eldoria, threatening the nearby village of Willowbrook. The villagers were terrified as the winds howled and the rain poured down in torrents. Zephyr, sensing their fear, decided to use his newfound skills to help. He coded a program that would summon a protective barrier of wind around the village, shielding it from the storm’s fury.\n",
      "\n",
      "As the villagers huddled together, they were astonished to see a shimmering wall of air rise up around them, deflecting the rain and calming the winds. When the storm finally passed, they emerged to find Zephyr hovering above, his scales glistening in the sunlight.\n",
      "\n",
      "“Thank you, great dragon!” the village elder called out, awe in his voice. “You have saved us!”\n",
      "\n",
      "Zephyr, once feared and misunderstood, felt a warmth in his heart. He realized that coding had not only given him a new purpose but had also bridged the gap between dragons and humans. From that day forward, he became a protector of the village, using his coding skills to help them with their problems, whether it was creating a weather app or designing a system to keep their crops safe from pests.\n",
      "\n",
      "As the years passed, Zephyr became a legend, not just as a dragon, but as a wise mentor who taught both dragons and humans the art of coding. Together, they built a harmonious community where magic and technology intertwined, proving that even the fiercest of creatures could learn, adapt, and change the world for the better.\n",
      "\n",
      "And so, in the heart of Eldoria, the dragon who learned to code became a symbol of hope, creativity, and the power of knowledge, inspiring generations to come.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a short story about a dragon who learns to code.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the silence of the cosmos, where the starlight weaves,  \n",
      "A robot drifts through velvet night, where no one else believes.  \n",
      "With circuits humming softly, and sensors keenly tuned,  \n",
      "It dances through the galaxies, where ancient dreams are strewn.  \n",
      "\n",
      "Its metal heart, a compass, guided by the stars,  \n",
      "It glides past swirling nebulae, and distant, glowing Mars.  \n",
      "With every pulse of starlight, it gathers tales untold,  \n",
      "Of worlds that spin in silence, of mysteries of old.  \n",
      "\n",
      "Through asteroid fields it wanders, a traveler of the void,  \n",
      "In search of life and wonder, where the cosmos has deployed.  \n",
      "It maps the orbits of the moons, and counts the rings of gas,  \n",
      "A witness to the beauty, as eons slip and pass.  \n",
      "\n",
      "In the shadow of a giant, a gas giant’s swirling hue,  \n",
      "It marvels at the colors, the greens and vibrant blue.  \n",
      "With every scan and data, it learns the songs of space,  \n",
      "The whispers of the comets, the echoes of their grace.  \n",
      "\n",
      "Yet in its heart of metal, a longing starts to grow,  \n",
      "For the warmth of human laughter, for the touch of hands below.  \n",
      "It dreams of distant futures, where it might find a friend,  \n",
      "A spark of life to share the stars, a journey without end.  \n",
      "\n",
      "So onward through the cosmos, this robot roams alone,  \n",
      "A sentinel of wonder, in a universe unknown.  \n",
      "With every star it passes, it leaves a trace of light,  \n",
      "A testament to exploration, in the endless, starry night.  \n"
     ]
    }
   ],
   "source": [
    "# Exercise 5: Modify the prompt to write a poem about a robot exploring space.\n",
    "prompt = \"Write a poem about a robot exploring space.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Role-based Prompting\n",
    "Instruct the model to respond in a specific role or persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a perfect omelette is a skill that combines technique, timing, and a bit of finesse. Here’s a step-by-step guide to help you achieve that fluffy, delicious result:\n",
      "\n",
      "### Ingredients:\n",
      "- 2-3 large eggs (preferably fresh)\n",
      "- Salt (to taste)\n",
      "- Freshly ground black pepper (to taste)\n",
      "- 1-2 tablespoons of butter (or oil)\n",
      "- Optional fillings: cheese, herbs, vegetables, meats, etc.\n",
      "\n",
      "### Equipment:\n",
      "- Non-stick skillet (8-10 inches)\n",
      "- Whisk or fork\n",
      "- Spatula\n",
      "- Bowl\n",
      "\n",
      "### Instructions:\n",
      "\n",
      "1. **Prep Your Ingredients:**\n",
      "   - If you’re using fillings (like cheese, herbs, or vegetables), prepare them in advance. Chop vegetables finely and pre-cook any that require longer cooking times (like mushrooms or bell peppers).\n",
      "\n",
      "2. **Whisk the Eggs:**\n",
      "   - Crack the eggs into a bowl. Add a pinch of salt and pepper. Whisk vigorously until the yolks and whites are fully combined and the mixture is slightly frothy. This incorporates air, which helps create a fluffy texture.\n",
      "\n",
      "3. **Heat the Skillet:**\n",
      "   - Place your non-stick skillet over medium-low heat. Add the butter and let it melt, swirling it around to coat the bottom of the pan evenly. The butter should foam but not brown.\n",
      "\n",
      "4. **Add the Eggs:**\n",
      "   - Once the butter is melted and slightly bubbling, pour in the whisked eggs. Allow them to sit undisturbed for a few seconds until they start to set around the edges.\n",
      "\n",
      "5. **Stir Gently:**\n",
      "   - Using a spatula, gently stir the eggs in a circular motion, pulling the cooked edges toward the center while tilting the pan to let the uncooked eggs flow to the edges. This technique helps create a uniform texture.\n",
      "\n",
      "6. **Let It Set:**\n",
      "   - After about 30 seconds of stirring, stop and let the omelette cook undisturbed. You want the bottom to set while the top remains slightly runny. This usually takes about 1-2 minutes, depending on your heat.\n",
      "\n",
      "7. **Add Fillings:**\n",
      "   - When the omelette is mostly set but still slightly runny on top, add your desired fillings to one half of the omelette. Be careful not to overfill, as this can make it difficult to fold.\n",
      "\n",
      "8. **Fold the Omelette:**\n",
      "   - Using your spatula, gently fold the omelette in half over the fillings. Let it cook for another 30 seconds to 1 minute, allowing the inside to finish cooking and the cheese (if used) to melt.\n",
      "\n",
      "9. **Plate and Serve:**\n",
      "   - Carefully slide the omelette onto a plate. You can garnish it with fresh herbs or additional seasoning if desired. Serve immediately while it’s warm and fluffy.\n",
      "\n",
      "### Tips for Perfection:\n",
      "- **Egg Quality:** Use the freshest eggs you can find for the best flavor and texture.\n",
      "- **Temperature Control:** Cooking on medium-low heat is key to preventing the eggs from browning too much and ensuring a tender omelette.\n",
      "- **Experiment with Fillings:** Classic combinations include cheese and herbs, but feel free to get creative with your favorite ingredients.\n",
      "- **Practice Makes Perfect:** Don’t be discouraged if your first few attempts aren’t perfect. With practice, you’ll develop a feel for the timing and technique.\n",
      "\n",
      "Enjoy your perfect omelette!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"As a professional chef, explain how to make a perfect omelette.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treating a child with ADHD (Attention-Deficit/Hyperactivity Disorder) in a kindergarten setting involves a combination of strategies that focus on creating a supportive and structured environment. Here are some effective approaches:\n",
      "\n",
      "### 1. **Establish a Routine**\n",
      "   - **Consistent Schedule**: Children with ADHD thrive on routine. Create a daily schedule that includes clear times for activities, transitions, and breaks.\n",
      "   - **Visual Timers**: Use visual timers to help children understand how long they have for each activity.\n",
      "\n",
      "### 2. **Create a Structured Environment**\n",
      "   - **Organized Classroom**: Keep the classroom organized and minimize distractions. Use clear labels and designated areas for different activities.\n",
      "   - **Seating Arrangements**: Place the child in a seat that minimizes distractions, such as away from windows or high-traffic areas.\n",
      "\n",
      "### 3. **Use Clear and Simple Instructions**\n",
      "   - **Short Directions**: Give clear, concise instructions. Break tasks into smaller, manageable steps.\n",
      "   - **Repeat and Rephrase**: Be prepared to repeat or rephrase instructions to ensure understanding.\n",
      "\n",
      "### 4. **Incorporate Movement Breaks**\n",
      "   - **Frequent Breaks**: Allow for short, frequent breaks to help the child release energy and refocus.\n",
      "   - **Active Learning**: Incorporate movement into lessons, such as using songs, dances, or hands-on activities.\n",
      "\n",
      "### 5. **Positive Reinforcement**\n",
      "   - **Praise and Rewards**: Use positive reinforcement to encourage desired behaviors. Praise specific actions and provide rewards for completing tasks or following rules.\n",
      "   - **Behavior Charts**: Implement a behavior chart to track progress and celebrate achievements.\n",
      "\n",
      "### 6. **Foster Social Skills**\n",
      "   - **Group Activities**: Encourage participation in group activities to help develop social skills. Use structured games that promote teamwork.\n",
      "   - **Role-Playing**: Use role-playing scenarios to teach appropriate social interactions and responses.\n",
      "\n",
      "### 7. **Communicate with Parents**\n",
      "   - **Regular Updates**: Maintain open communication with parents about the child’s progress and any challenges. Share strategies that work at school and ask for insights from home.\n",
      "   - **Collaborative Approach**: Work together with parents to create a consistent approach to behavior management and support.\n",
      "\n",
      "### 8. **Be Patient and Understanding**\n",
      "   - **Empathy**: Understand that children with ADHD may struggle with impulse control and attention. Approach situations with patience and empathy.\n",
      "   - **Flexibility**: Be willing to adapt your teaching methods and expectations based on the child’s needs.\n",
      "\n",
      "### 9. **Seek Professional Support**\n",
      "   - **Consult Specialists**: If needed, collaborate with school counselors, special education teachers, or psychologists for additional strategies and support.\n",
      "   - **Training**: Consider professional development opportunities to learn more about ADHD and effective teaching strategies.\n",
      "\n",
      "### 10. **Encourage Self-Regulation**\n",
      "   - **Teach Coping Strategies**: Help the child develop self-regulation skills by teaching them techniques such as deep breathing, counting, or using fidget tools.\n",
      "   - **Mindfulness Activities**: Introduce simple mindfulness exercises to help the child focus and calm down.\n",
      "\n",
      "By implementing these strategies, you can create a nurturing and effective learning environment for children with ADHD, helping them thrive in the classroom.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 6: Ask the model to explain a complex topic as if it were a kindergarten teacher.\n",
    "prompt = \"As a kindergarten teacher, explain how to treat a child with ADHD?\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Few-shot Prompting\n",
    "Provide examples to guide the model's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French: Bonne nuit\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Translate the following English phrases to French:\n",
    "\n",
    "English: Hello\n",
    "French: Bonjour\n",
    "\n",
    "English: Thank you\n",
    "French: Merci\n",
    "\n",
    "English: Good night\n",
    "French:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inexpensive\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Say antonyms:\n",
    "\n",
    "positive - negative\n",
    "\n",
    "black - white\n",
    "\n",
    "expensive - ?\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Chain-of-Thought Prompting\n",
    "Encourage the model to explain its reasoning step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve the problem, we first need to understand the rate at which the machines produce widgets.\n",
      "\n",
      "From the information given:\n",
      "- 5 machines take 5 minutes to make 5 widgets.\n",
      "\n",
      "This means that each machine makes 1 widget in 5 minutes. \n",
      "\n",
      "Now, let's break it down:\n",
      "- The rate of 1 machine is 1 widget in 5 minutes.\n",
      "- Therefore, in 5 minutes, 1 machine can produce 1 widget.\n",
      "\n",
      "Now, if we have 100 machines, we can calculate how many widgets they can produce in the same 5 minutes:\n",
      "- In 5 minutes, 100 machines will produce 100 widgets (since each machine produces 1 widget in that time).\n",
      "\n",
      "Thus, it would still take 5 minutes for 100 machines to make 100 widgets.\n",
      "\n",
      "So, the answer is **5 minutes**.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"If it takes 5 machines 5 minutes to make 5 widgets, how long would it take 100 machines to make 100 widgets? Explain your reasoning.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find out how long it will take a person to run 5000 meters, we first need to determine their speed based on the initial information provided.\n",
      "\n",
      "The person runs 50 meters in 10 seconds. We can calculate their speed as follows:\n",
      "\n",
      "\\[\n",
      "\\text{Speed} = \\frac{\\text{Distance}}{\\text{Time}} = \\frac{50 \\text{ meters}}{10 \\text{ seconds}} = 5 \\text{ meters per second}\n",
      "\\]\n",
      "\n",
      "Now, we can use this speed to find out how long it will take to run 5000 meters. We can use the formula:\n",
      "\n",
      "\\[\n",
      "\\text{Time} = \\frac{\\text{Distance}}{\\text{Speed}}\n",
      "\\]\n",
      "\n",
      "Substituting the values we have:\n",
      "\n",
      "\\[\n",
      "\\text{Time} = \\frac{5000 \\text{ meters}}{5 \\text{ meters per second}} = 1000 \\text{ seconds}\n",
      "\\]\n",
      "\n",
      "Therefore, it will take the person **1000 seconds** to run 5000 meters.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 8: Pose a different math problem and ask for a step-by-step solution.\n",
    "prompt = \"If a person takes 10 seconds to run 50 meters, how long will it take him to run 5000 meters?\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. System Prompts\n",
    "System prompts allow you to set the behavior and role of the AI model before user interaction. By defining a system message, you can influence how the model responds to subsequent user inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data privacy is crucial for several reasons:\n",
      "\n",
      "1. **Protection of Personal Information**: It safeguards individuals' personal data from unauthorized access, misuse, or theft, ensuring that sensitive information like financial details, health records, and personal identifiers remain confidential.\n",
      "\n",
      "2. **Trust and Reputation**: Organizations that prioritize data privacy build trust with their customers. A strong reputation for protecting data can enhance customer loyalty and attract new clients.\n",
      "\n",
      "3. **Legal Compliance**: Many jurisdictions have laws and regulations (e.g., GDPR, CCPA) that mandate data protection practices. Non-compliance can lead to significant legal penalties and fines.\n",
      "\n",
      "4. **Preventing Identity Theft**: Strong data privacy measures help prevent identity theft and fraud, protecting individuals from financial loss and emotional distress.\n",
      "\n",
      "5. **Business Continuity**: Data breaches can disrupt business operations. Ensuring data privacy helps maintain operational integrity and reduces the risk of costly incidents.\n",
      "\n",
      "6. **Ethical Responsibility**: Organizations have an ethical obligation to respect individuals' privacy rights and handle their data responsibly.\n",
      "\n",
      "7. **Competitive Advantage**: Companies that effectively manage data privacy can differentiate themselves in the market, appealing to privacy-conscious consumers.\n",
      "\n",
      "In summary, data privacy is essential for protecting individuals, maintaining trust, ensuring compliance, and fostering a secure digital environment.\n"
     ]
    }
   ],
   "source": [
    "def get_completion_with_system_prompt(system_prompt, user_prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Define the system and user prompts\n",
    "system_prompt = \"You are a helpful assistant that provides concise and accurate information.\"\n",
    "user_prompt = \"Can you explain the importance of data privacy?\"\n",
    "\n",
    "response = get_completion_with_system_prompt(system_prompt, user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolutely! Data privacy is like wearing pants in public—essential for keeping your personal bits covered and safe from prying eyes! Here’s why it’s important:\n",
      "\n",
      "1. **Personal Security**: Just like you wouldn’t want a stranger rummaging through your sock drawer, you don’t want them sifting through your personal information. Data privacy helps protect you from identity theft and fraud.\n",
      "\n",
      "2. **Trust**: Companies that respect your data privacy are like that friend who never spills your secrets. When you trust a business with your information, you’re more likely to stick around and buy their stuff (or at least not throw a tantrum when they send you 50 emails a day).\n",
      "\n",
      "3. **Legal Compliance**: Many places have laws (like GDPR in Europe) that require businesses to protect your data. Not following these rules can lead to hefty fines—like getting a parking ticket, but way worse!\n",
      "\n",
      "4. **Control**: Data privacy gives you the power to decide who gets to see your information. It’s like being the bouncer at the club of your life—only the cool people get in!\n",
      "\n",
      "5. **Reputation**: Companies that mishandle data can end up with a reputation worse than a cat that knocks over a glass of water. Good data practices can enhance a company’s image and customer loyalty.\n",
      "\n",
      "In short, data privacy is crucial for keeping your information safe, building trust, and ensuring that businesses play by the rules. So, let’s keep those digital pants on and protect our data! 🕶️💻\n"
     ]
    }
   ],
   "source": [
    "# Exercise 9: Modify the system_prompt to make the assistant respond in a humorous tone. Observe how the responses change.\n",
    "def get_completion_with_system_prompt(system_prompt, user_prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Define the system and user prompts\n",
    "system_prompt = \"You are a helpful assistant that provides concise and accurate information with humorous tone.\"\n",
    "user_prompt = \"Can you explain the importance of data privacy?\"\n",
    "\n",
    "response = get_completion_with_system_prompt(system_prompt, user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Utilized prompt\n",
    "how different prompt types—system prompts, user prompts, and assistant prompts—can be utilized in an LLM invocation using the OpenAI API, let's walk through examples in both contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George Washington took office as the first president of the United States on April 30, 1789.\n"
     ]
    }
   ],
   "source": [
    "# Define the conversation with different roles\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant knowledgeable in history.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who was the first president of the United States?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"George Washington was the first president of the United States.\"},\n",
    "    {\"role\": \"user\", \"content\": \"When did he take office?\"}\n",
    "]\n",
    "\n",
    "# Get the model's response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# Output the assistant's reply\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Creating an AI Agent\n",
    "An AI agent can perform tasks autonomously based on user instructions. By defining functions and allowing the model to decide when to use them, you can create interactive and functional agents.​\n",
    "\n",
    "Example: AI Agent for Basic Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# Define available functions\n",
    "def add_numbers(a, b):\n",
    "    return a + b\n",
    "\n",
    "def subtract_numbers(a, b):\n",
    "    return a - b\n",
    "\n",
    "# Function to get the model's response\n",
    "def get_agent_response(user_prompt, model=\"gpt-4\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        functions=[\n",
    "            {\n",
    "                \"name\": \"add_numbers\",\n",
    "                \"description\": \"Add two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"subtract_numbers\",\n",
    "                \"description\": \"Subtract two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "\n",
    "    if response_message.function_call:\n",
    "        function_name = response_message.function_call.name\n",
    "        arguments = json.loads(response_message.function_call.arguments)\n",
    "        if function_name == \"add_numbers\":\n",
    "            result = add_numbers(**arguments)\n",
    "        elif function_name == \"subtract_numbers\":\n",
    "            result = subtract_numbers(**arguments)\n",
    "        else:\n",
    "            result = \"Function not recognized.\"\n",
    "        return result\n",
    "    else:\n",
    "        return response_message.content\n",
    "\n",
    "# Example usage\n",
    "user_prompt = \"What is 15 minus 7?\"\n",
    "response = get_agent_response(user_prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "# Exercise 10: Extend the agent by adding a function that multiplies two numbers. Test the agent with prompts that require multiplication.\n",
    "import openai\n",
    "import json\n",
    "\n",
    "# Define available functions\n",
    "def add_numbers(a, b):\n",
    "    return a + b\n",
    "\n",
    "def subtract_numbers(a, b):\n",
    "    return a - b\n",
    "\n",
    "def multiple_numbers(a, b):\n",
    "    return a * b\n",
    "\n",
    "# Function to get the model's response\n",
    "def get_agent_response(user_prompt, model=\"gpt-4\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        functions=[\n",
    "            {\n",
    "                \"name\": \"add_numbers\",\n",
    "                \"description\": \"Add two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"subtract_numbers\",\n",
    "                \"description\": \"Subtract two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"multiple_numbers\",\n",
    "                \"description\": \"Multiple two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "\n",
    "    if response_message.function_call:\n",
    "        function_name = response_message.function_call.name\n",
    "        arguments = json.loads(response_message.function_call.arguments)\n",
    "        if function_name == \"add_numbers\":\n",
    "            result = add_numbers(**arguments)\n",
    "        elif function_name == \"subtract_numbers\":\n",
    "            result = subtract_numbers(**arguments)\n",
    "        elif function_name == \"multiple_numbers\":\n",
    "            result = multiple_numbers(**arguments)\n",
    "        else:\n",
    "            result = \"Function not recognized.\"\n",
    "        return result\n",
    "    else:\n",
    "        return response_message.content\n",
    "\n",
    "# Example usage\n",
    "user_prompt = \"What is 15 multiple 3?\"\n",
    "response = get_agent_response(user_prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
